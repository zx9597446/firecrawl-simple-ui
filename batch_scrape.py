import os
import requests
import streamlit as st
from dotenv import load_dotenv
import json
from time import sleep

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()
API_URL = os.getenv("FIRECRAWL_API_URL", "https://api.firecrawl.dev/v1")
API_KEY = os.getenv("FIRECRAWL_API_KEY")

# åˆå§‹åŒ–sessionçŠ¶æ€
if 'job_id' not in st.session_state:
    st.session_state.job_id = None
if 'results' not in st.session_state:
    st.session_state.results = None

def submit_batch_job(urls):
    """æäº¤æ‰¹é‡æŠ“å–ä»»åŠ¡"""
    headers = {
        "Authorization": f"Bearer {API_KEY}",
        "Content-Type": "application/json"
    }
    payload = {
        "urls": urls,
        "formats": ["markdown"],
        "onlyMainContent": True,
        "blockAds": True
    }
    
    try:
        response = requests.post(
            f"{API_URL}/batch/scrape",
            headers=headers,
            json=payload
        )
        response.raise_for_status()
        return response.json()
    except Exception as e:
        st.error(f"æäº¤å¤±è´¥: {str(e)}")
        return None

def get_job_results(job_id):
    """è·å–ä»»åŠ¡ç»“æœ"""
    headers = {"Authorization": f"Bearer {API_KEY}"}
    try:
        response = requests.get(
            f"{API_URL}/batch/scrape/{job_id}",
            headers=headers
        )
        response.raise_for_status()
        return response.json()
    except Exception as e:
        st.error(f"è·å–ç»“æœå¤±è´¥: {str(e)}")
        return None

# Streamlitç•Œé¢
st.title("ğŸ”¥ Firecrawl æ‰¹é‡æŠ“å–å·¥å…·")

# URLè¾“å…¥æ¡†
urls = st.text_area(
    "è¾“å…¥è¦æŠ“å–çš„URLï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰",
    height=150,
    help="æ¯ä¸ªURLå•ç‹¬ä¸€è¡Œ"
).split('\n')

# æäº¤æŒ‰é’®
if st.button("å¼€å§‹æŠ“å–") and urls:
    with st.spinner("æäº¤ä»»åŠ¡ä¸­..."):
        result = submit_batch_job([u.strip() for u in urls if u.strip()])
        
    if result and result.get("success"):
        st.session_state.job_id = result["id"]
        st.success(f"ä»»åŠ¡å·²æäº¤ï¼ä½œä¸šID: {result['id']}")
        if result.get("invalidURLs"):
            st.warning(f"æ— æ•ˆURL: {', '.join(result['invalidURLs'])}")
    else:
        st.error("ä»»åŠ¡æäº¤å¤±è´¥")

# ç»“æœæ˜¾ç¤ºå’Œä¸‹è½½
if st.session_state.job_id:
    st.divider()
    st.subheader("æŠ“å–ç»“æœ")
    
    if st.button("æ£€æŸ¥è¿›åº¦"):
        with st.spinner("è·å–ç»“æœä¸­..."):
            results = get_job_results(st.session_state.job_id)
            
        if results:
            if results["status"] == "completed":
                st.session_state.results = results
                st.success("æŠ“å–å®Œæˆï¼")
                
                # æ˜¾ç¤ºå¹¶ä¸‹è½½Markdown
                for idx, item in enumerate(results["data"]):
                    with st.expander(f"ç»“æœ {idx+1}: {item['metadata']['sourceURL']}"):
                        st.code(item["markdown"], language="markdown")
                        
                        # ä¸‹è½½æŒ‰é’®
                        st.download_button(
                            label="ä¸‹è½½Markdown",
                            data=item["markdown"],
                            file_name=f"content_{idx+1}.md",
                            key=f"dl_{idx}"
                        )
            else:
                st.info(f"å¤„ç†ä¸­... å®Œæˆ {results['completed']}/{results['total']}")
                st.progress(results["completed"] / results["total"])