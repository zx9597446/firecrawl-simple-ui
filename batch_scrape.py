import os
import requests
import streamlit as st
from dotenv import load_dotenv
import json
from time import sleep

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()
API_URL = os.getenv("FIRECRAWL_API_URL", "https://api.firecrawl.dev/v1")
API_KEY = os.getenv("FIRECRAWL_API_KEY")

# åˆå§‹åŒ–sessionçŠ¶æ€
if 'job_id' not in st.session_state:
    st.session_state.job_id = None
if 'results' not in st.session_state:
    st.session_state.results = None

def submit_batch_job(urls, options):
    """æäº¤æ‰¹é‡æŠ“å–ä»»åŠ¡"""
    headers = {
        "Authorization": f"Bearer {API_KEY}",
        "Content-Type": "application/json"
    }
    payload = {
        "urls": urls,
        "formats": options["formats"],
        "onlyMainContent": options["only_main_content"],
        "blockAds": options["block_ads"],
        "ignoreInvalidURLs": options["ignore_invalid_urls"],
        "waitFor": options["wait_for"],
        "timeout": options["timeout"],
        "removeBase64Images": options["remove_base64_images"],
        "mobile": options["mobile"],
        "skipTlsVerification": options["skip_tls_verification"]
    }
    
    # å¯é€‰å‚æ•°
    if options["include_tags"]:
        payload["includeTags"] = options["include_tags"].split(',')
    if options["exclude_tags"]:
        payload["excludeTags"] = options["exclude_tags"].split(',')

    # æ·»åŠ é¡µé¢æ“ä½œ
    try:
        payload["actions"] = json.loads(options["actions"])
    except json.JSONDecodeError:
        st.error("é¡µé¢æ“ä½œå¿…é¡»æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼")

    # æ·»åŠ ä½ç½®è®¾ç½®
    payload["location"] = {
        "country": options["location_country"],
        "languages": [lang.strip() for lang in options["location_languages"].split(",")]
    }
    
    try:
        response = requests.post(
            f"{API_URL}/batch/scrape",
            headers=headers,
            json=payload
        )
        response.raise_for_status()
        return response.json()
    except Exception as e:
        st.error(f"æäº¤å¤±è´¥: {str(e)}")
        return None

def get_job_results(job_id):
    """è·å–ä»»åŠ¡ç»“æœ"""
    headers = {"Authorization": f"Bearer {API_KEY}"}
    try:
        response = requests.get(
            f"{API_URL}/batch/scrape/{job_id}",
            headers=headers
        )
        response.raise_for_status()
        return response.json()
    except Exception as e:
        st.error(f"è·å–ç»“æœå¤±è´¥: {str(e)}")
        return None

def poll_job_status(job_id):
    """è½®è¯¢ä»»åŠ¡çŠ¶æ€ç›´åˆ°å®Œæˆ"""
    placeholder = st.empty()
    while True:
        results = get_job_results(job_id)
        if not results:
            return None
            
        if results["status"] == "completed":
            placeholder.empty()
            return results
            
        # æ›´æ–°è¿›åº¦
        progress = results["completed"] / results["total"]
        placeholder.progress(progress, text=f"å¤„ç†ä¸­... å®Œæˆ {results['completed']}/{results['total']}")
        sleep(2)  # æ¯2ç§’æ£€æŸ¥ä¸€æ¬¡

# Streamlitç•Œé¢
st.title("ğŸ”¥ Firecrawl æ‰¹é‡æŠ“å–å·¥å…·")

# é…ç½®é€‰é¡¹
with st.expander("é«˜çº§æŠ“å–é€‰é¡¹"):
    col1, col2 = st.columns(2)
    with col1:
        formats = st.multiselect(
            "è¾“å‡ºæ ¼å¼",
            ["markdown", "html", "rawHtml", "links", "screenshot"],
            default=["markdown"]
        )
        only_main_content = st.checkbox("ä»…ä¸»è¦å†…å®¹", value=True)
        block_ads = st.checkbox("å±è”½å¹¿å‘Š", value=True)
        ignore_invalid_urls = st.checkbox("å¿½ç•¥æ— æ•ˆURL", value=True)
        remove_base64_images = st.checkbox("ç§»é™¤Base64å›¾ç‰‡", value=False)
        
    with col2:
        wait_for = st.number_input("ç­‰å¾…æ—¶é—´(ms)", min_value=0, value=1000)
        timeout = st.number_input("è¶…æ—¶æ—¶é—´(ms)", min_value=1000, value=60000)
        mobile = st.checkbox("ç§»åŠ¨è®¾å¤‡æ¨¡å¼", value=False)
        skip_tls_verification = st.checkbox("è·³è¿‡TLSéªŒè¯", value=False)
        
    include_tags = st.text_input("åŒ…å«æ ‡ç­¾(é€—å·åˆ†éš”)") 
    exclude_tags = st.text_input("æ’é™¤æ ‡ç­¾(é€—å·åˆ†éš”)")

    st.subheader("é¡µé¢æ“ä½œ")
    actions = st.text_area(
        "é¡µé¢æ“ä½œ(JSONæ ¼å¼)",
        value='[]',
        help='ä¾‹å¦‚: [{"type": "wait", "milliseconds": 2000}, {"type": "click", "selector": "#load-more"}]'
    )

    st.subheader("ä½ç½®è®¾ç½®")
    location_country = st.selectbox(
        "å›½å®¶ä»£ç ",
        ["CN", "US", "AU", "DE", "JP"],
        index=0,
        help="ISO 3166-1 alpha-2 country code (e.g., 'US', 'AU', 'DE', 'JP')"
    )
    location_languages = st.text_input(
        "è¯­è¨€åå¥½",
        value="zh-CN,zh",
        help="Preferred languages and locales for the request in order of priority"
    )

# URLè¾“å…¥æ¡†
urls = st.text_area(
    "è¾“å…¥è¦æŠ“å–çš„URLï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰",
    height=150,
    help="æ¯ä¸ªURLå•ç‹¬ä¸€è¡Œ"
).split('\n')

# æäº¤æŒ‰é’®
if st.button("å¼€å§‹æŠ“å–") and urls:
    options = {
        "formats": formats,
        "only_main_content": only_main_content,
        "block_ads": block_ads,
        "ignore_invalid_urls": ignore_invalid_urls,
        "wait_for": wait_for,
        "timeout": timeout,
        "remove_base64_images": remove_base64_images,
        "mobile": mobile,
        "skip_tls_verification": skip_tls_verification,
        "include_tags": include_tags,
        "exclude_tags": exclude_tags,
        "actions": actions,
        "location_country": location_country,
        "location_languages": location_languages
    }
    
    with st.spinner("æäº¤ä»»åŠ¡ä¸­..."):
        result = submit_batch_job([u.strip() for u in urls if u.strip()], options)
        
    if result and result.get("success"):
        st.session_state.job_id = result["id"]
        st.success(f"ä»»åŠ¡å·²æäº¤ï¼ä½œä¸šID: {result['id']}")
        if result.get("invalidURLs"):
            st.warning(f"æ— æ•ˆURL: {', '.join(result['invalidURLs'])}")
    else:
        st.error("ä»»åŠ¡æäº¤å¤±è´¥")

# ç»“æœæ˜¾ç¤ºå’Œä¸‹è½½
if st.session_state.job_id:
    st.divider()
    st.subheader("æŠ“å–ç»“æœ")
    
    with st.spinner("è·å–ç»“æœä¸­..."):
        results = poll_job_status(st.session_state.job_id)
            
        if results:
            st.session_state.results = results
            st.success("æŠ“å–å®Œæˆï¼")
            
            if not results.get("data"):
                st.warning("æ²¡æœ‰è·å–åˆ°ä»»ä½•ç»“æœæ•°æ®")
                continue
            
            # åˆå¹¶æ‰€æœ‰æœ‰æ•ˆå†…å®¹
            valid_results = []
            for item in results["data"]:
                if not item:
                    continue
                    
                source_url = item.get("metadata", {}).get("sourceURL", "æœªçŸ¥URL")
                if item.get("error"):
                    valid_results.append(f"# {source_url}\n\né”™è¯¯: {item['error']}")
                elif "markdown" in item:
                    valid_results.append(f"# {source_url}\n\n{item['markdown']}")
                elif "html" in item:
                    valid_results.append(f"# {source_url}\n\nHTMLå†…å®¹å·²è·å–ä½†æœªæ˜¾ç¤º")
                else:
                    valid_results.append(f"# {source_url}\n\næ— å¯ç”¨å†…å®¹")
            
            if valid_results:
                combined_md = "\n\n---\n\n".join(valid_results)
                
                # ä¸‹è½½åˆå¹¶çš„MarkdownæŒ‰é’®
                st.download_button(
                    label="ä¸‹è½½å…¨éƒ¨ç»“æœ",
                    data=combined_md,
                    file_name="combined_results.md",
                    key="dl_all"
                )
                
                # æ˜¾ç¤ºå¹¶ä¸‹è½½å•ä¸ªç»“æœ
                for idx, item in enumerate(results["data"]):
                    if not item:
                        continue
                        
                    source_url = item.get("metadata", {}).get("sourceURL", f"ç»“æœ {idx+1}")
                    with st.expander(f"{source_url} - çŠ¶æ€ç : {item.get('metadata', {}).get('statusCode', 'æœªçŸ¥')}"):
                        if item.get("error"):
                            st.error(f"é”™è¯¯: {item['error']}")
                        elif "markdown" in item:
                            st.code(item["markdown"], language="markdown")
                            st.download_button(
                                label="ä¸‹è½½æ­¤å†…å®¹",
                                data=item["markdown"],
                                file_name=f"content_{idx+1}.md",
                                key=f"dl_{idx}"
                            )
                        elif "html" in item:
                            st.warning("è·å–åˆ°HTMLå†…å®¹ä½†æœªæ˜¾ç¤º")
                        else:
                            st.warning("æ— å¯ç”¨å†…å®¹")
            else:
                st.warning("æ²¡æœ‰æœ‰æ•ˆçš„æŠ“å–ç»“æœ")
