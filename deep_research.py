import os
import requests
import streamlit as st
from dotenv import load_dotenv
from time import sleep

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()
API_URL = os.getenv("FIRECRAWL_API_URL", "https://api.firecrawl.dev/v1")
API_KEY = os.getenv("FIRECRAWL_API_KEY")

# åˆå§‹åŒ–sessionçŠ¶æ€
if 'job_id' not in st.session_state:
    st.session_state.job_id = None
if 'results' not in st.session_state:
    st.session_state.results = None

def submit_deep_research(query, options):
    """æäº¤æ·±åº¦ç ”ç©¶ä»»åŠ¡"""
    headers = {
        "Authorization": f"Bearer {API_KEY}",
        "Content-Type": "application/json"
    }
    payload = {
        "query": query,
        "maxDepth": options["max_depth"],
        "timeLimit": options["time_limit"],
        "maxUrls": options["max_urls"]
    }

    try:
        response = requests.post(
            f"{API_URL}/deep-research",
            headers=headers,
            json=payload
        )
        response.raise_for_status()
        return response.json()
    except Exception as e:
        st.error(f"æäº¤å¤±è´¥: {str(e)}")
        return None

def get_job_results(job_id):
    """è·å–ä»»åŠ¡ç»“æœ"""
    headers = {"Authorization": f"Bearer {API_KEY}"}
    try:
        response = requests.get(
            f"{API_URL}/deep-research/{job_id}",
            headers=headers
        )
        response.raise_for_status()
        return response.json()
    except Exception as e:
        st.error(f"è·å–ç»“æœå¤±è´¥: {str(e)}")
        return None

def poll_job_status(job_id):
    """è½®è¯¢ä»»åŠ¡çŠ¶æ€ç›´åˆ°å®Œæˆæˆ–å¤±è´¥"""
    placeholder = st.empty()
    max_attempts = 60  # æœ€å¤§å°è¯•æ¬¡æ•° (çº¦10åˆ†é’Ÿï¼Œæ¯10ç§’æ£€æŸ¥ä¸€æ¬¡)
    attempts = 0
    
    while attempts < max_attempts:
        results = get_job_results(job_id)
        if not results:
            placeholder.error("æ— æ³•è·å–ä»»åŠ¡çŠ¶æ€")
            return None
            
        status = results.get("status")
        if status == "completed":
            placeholder.empty()
            return results
        elif status == "failed":
            placeholder.error(f"ç ”ç©¶ä»»åŠ¡å¤±è´¥: {results.get('message', 'æœªçŸ¥é”™è¯¯')}")
            return None
            
        # æ˜¾ç¤ºå½“å‰æ´»åŠ¨çŠ¶æ€
        current_activity = results.get("data", {}).get("activities", [{}])[-1]
        status_text = f"å¤„ç†ä¸­...\nå½“å‰æ·±åº¦: {results.get('currentDepth', 0)}/{results.get('maxDepth', 0)}\n"
        status_text += f"æ´»åŠ¨: {current_activity.get('type', 'unknown')} - {current_activity.get('message', '')}"
        status_text += f"\nå°è¯• {attempts+1}/{max_attempts}"
        
        placeholder.text(status_text)
        sleep(10)  # æ¯10ç§’æ£€æŸ¥ä¸€æ¬¡
        attempts += 1
        
    placeholder.error("ç ”ç©¶ä»»åŠ¡è¶…æ—¶")
    return None

# Streamlitç•Œé¢
st.title("ğŸ” Firecrawl æ·±åº¦ç ”ç©¶å·¥å…·")

# ç ”ç©¶æŸ¥è¯¢è¾“å…¥
query = st.text_area(
    "è¾“å…¥ç ”ç©¶é—®é¢˜",
    height=100,
    placeholder="ä¾‹å¦‚: What are the latest developments in quantum computing?",
    help="è¾“å…¥æ‚¨æƒ³è¦ç ”ç©¶çš„ä¸»é¢˜æˆ–é—®é¢˜"
)

# é…ç½®é€‰é¡¹
with st.expander("ç ”ç©¶å‚æ•°"):
    col1, col2 = st.columns(2)
    with col1:
        max_depth = st.number_input("æœ€å¤§æ·±åº¦", min_value=1, max_value=10, value=7)
        max_urls = st.number_input("æœ€å¤§URLæ•°é‡", min_value=1, max_value=1000, value=20)
    with col2:
        time_limit = st.number_input("æ—¶é—´é™åˆ¶(ç§’)", min_value=30, max_value=300, value=270)

# æäº¤æŒ‰é’®
if st.button("å¼€å§‹ç ”ç©¶") and query:
    options = {
        "max_depth": max_depth,
        "time_limit": time_limit,
        "max_urls": max_urls
    }
    
    with st.spinner("æäº¤ä»»åŠ¡ä¸­..."):
        result = submit_deep_research(query.strip(), options)
        
    if not result:
        st.error("ä»»åŠ¡æäº¤å¤±è´¥: æ— å“åº”")
    elif result.get("error"):
        st.error(f"ä»»åŠ¡æäº¤å¤±è´¥: {result['error']}")
    elif not result.get("success"):
        st.error(f"ä»»åŠ¡æäº¤å¤±è´¥: {result.get('message', 'æœªçŸ¥é”™è¯¯')}")
    elif not result.get("id"):
        st.error("ä»»åŠ¡æäº¤å¤±è´¥: æœªè¿”å›ä½œä¸šID")
        
    st.session_state.job_id = result["id"]
    st.success(f"ç ”ç©¶ä»»åŠ¡å·²æäº¤ï¼ä½œä¸šID: {result['id']}")

# ç»“æœæ˜¾ç¤º
if st.session_state.job_id:
    st.divider()
    st.subheader("ç ”ç©¶ç»“æœ")
    
    with st.spinner("è·å–ç»“æœä¸­..."):
        results = poll_job_status(st.session_state.job_id)
            
        if results:
            st.session_state.results = results
            st.success("ç ”ç©¶å®Œæˆï¼")
            
            if not results.get("data"):
                st.warning("æ²¡æœ‰è·å–åˆ°ä»»ä½•ç»“æœæ•°æ®")
                
            # æ˜¾ç¤ºæœ€ç»ˆåˆ†æ
            final_analysis = results["data"].get("finalAnalysis")
            if final_analysis:
                st.subheader("æœ€ç»ˆåˆ†æ")
                st.markdown(final_analysis)
                
                # ä¸‹è½½æŒ‰é’®
                st.download_button(
                    label="ä¸‹è½½åˆ†æç»“æœ",
                    data=final_analysis,
                    file_name="research_analysis.md",
                    key="dl_analysis"
                )
            
            # æ˜¾ç¤ºæ¥æº
            sources = results["data"].get("sources", [])
            if sources:
                st.subheader("ç ”ç©¶æ¥æº")
                for source in sources:
                    with st.expander(f"{source.get('title', 'æ— æ ‡é¢˜')}"):
                        st.markdown(f"**URL**: {source.get('url', 'æœªçŸ¥')}")
                        st.markdown(f"**æè¿°**: {source.get('description', 'æ— æè¿°')}")
